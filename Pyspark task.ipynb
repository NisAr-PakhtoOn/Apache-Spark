{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd8ef047",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|hello|\n",
      "+-----+\n",
      "|spark|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark as ps\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.getOrCreate()\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "df=spark.sql(\"select 'spark' as hello\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a830dc",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "878124c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|             Reviews|labels|\n",
      "+--------------------+------+\n",
      "|Wow... Loved this...|     1|\n",
      "|  Crust is not good.|     0|\n",
      "|Not tasty and the...|     0|\n",
      "|Stopped by during...|     1|\n",
      "|The selection on ...|     1|\n",
      "|Now I am getting ...|     0|\n",
      "|Honeslty it didn'...|     0|\n",
      "|The potatoes were...|     0|\n",
      "|The fries were gr...|     1|\n",
      "|      A great touch.|     1|\n",
      "|Service was very ...|     1|\n",
      "|  Would not go back.|     0|\n",
      "|The cashier had n...|     0|\n",
      "|I tried the Cape ...|     1|\n",
      "|I was disgusted b...|     0|\n",
      "|I was shocked bec...|     0|\n",
      "| Highly recommended.|     1|\n",
      "|Waitress was a li...|     0|\n",
      "|This place is not...|     0|\n",
      "|did not like at all.|     0|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv(\"helloj1.csv\",header=True,inferSchema=True)\n",
    "data.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00d7b75",
   "metadata": {},
   "source": [
    "# Tokenize Reviews Text into Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea19e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer,RegexTokenizer\n",
    "from pyspark.sql.functions import col,udf \n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6eec979",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(inputCol=\"Reviews\",outputCol=\"words\")\n",
    "regexTokenizer=RegexTokenizer(inputCol=\"Reviews\",outputCol=\"words\",pattern=\"\\\\W\")\n",
    "\n",
    "countTokens=udf(lambda w: len(w), IntegerType())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbffb142",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized=tokenizer.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df35b917",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+\n",
      "|             Reviews|labels|               words|\n",
      "+--------------------+------+--------------------+\n",
      "|Wow... Loved this...|     1|[wow..., loved, t...|\n",
      "|  Crust is not good.|     0|[crust, is, not, ...|\n",
      "|Not tasty and the...|     0|[not, tasty, and,...|\n",
      "|Stopped by during...|     1|[stopped, by, dur...|\n",
      "|The selection on ...|     1|[the, selection, ...|\n",
      "|Now I am getting ...|     0|[now, i, am, gett...|\n",
      "|Honeslty it didn'...|     0|[honeslty, it, di...|\n",
      "|The potatoes were...|     0|[the, potatoes, w...|\n",
      "|The fries were gr...|     1|[the, fries, were...|\n",
      "|      A great touch.|     1|  [a, great, touch.]|\n",
      "|Service was very ...|     1|[service, was, ve...|\n",
      "|  Would not go back.|     0|[would, not, go, ...|\n",
      "|The cashier had n...|     0|[the, cashier, ha...|\n",
      "|I tried the Cape ...|     1|[i, tried, the, c...|\n",
      "|I was disgusted b...|     0|[i, was, disguste...|\n",
      "|I was shocked bec...|     0|[i, was, shocked,...|\n",
      "| Highly recommended.|     1|[highly, recommen...|\n",
      "|Waitress was a li...|     0|[waitress, was, a...|\n",
      "|This place is not...|     0|[this, place, is,...|\n",
      "|did not like at all.|     0|[did, not, like, ...|\n",
      "+--------------------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92496bee",
   "metadata": {},
   "source": [
    "# Transform the reviews text data into numeric features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e470bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "087fcb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e5eeb36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------+------+--------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------+\n",
      "|Reviews                                                                                                        |labels|words                                                                                                                                 |hashedValues                                                                                     |\n",
      "+---------------------------------------------------------------------------------------------------------------+------+--------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------+\n",
      "|Wow... Loved this place.                                                                                       |1     |[wow..., loved, this, place.]                                                                                                         |(16,[3,6,13],[1.0,1.0,2.0])                                                                      |\n",
      "|Crust is not good.                                                                                             |0     |[crust, is, not, good.]                                                                                                               |(16,[7,9,10,13],[1.0,1.0,1.0,1.0])                                                               |\n",
      "|Not tasty and the texture was just nasty.                                                                      |0     |[not, tasty, and, the, texture, was, just, nasty.]                                                                                    |(16,[1,3,6,11,13],[3.0,1.0,1.0,2.0,1.0])                                                         |\n",
      "|Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.                        |1     |[stopped, by, during, the, late, may, bank, holiday, off, rick, steve, recommendation, and, loved, it.]                               |(16,[0,1,2,6,7,8,11,13,15],[1.0,1.0,1.0,1.0,3.0,1.0,1.0,4.0,2.0])                                |\n",
      "|The selection on the menu was great and so were the prices.                                                    |1     |[the, selection, on, the, menu, was, great, and, so, were, the, prices.]                                                              |(16,[1,2,3,5,8,10,11,14],[3.0,1.0,2.0,1.0,1.0,1.0,2.0,1.0])                                      |\n",
      "|Now I am getting angry and I want my damn pho.                                                                 |0     |[now, i, am, getting, angry, and, i, want, my, damn, pho.]                                                                            |(16,[0,1,3,10,11,12,13,14],[2.0,1.0,1.0,1.0,1.0,3.0,1.0,1.0])                                    |\n",
      "|Honeslty it didn't taste THAT fresh.)                                                                          |0     |[honeslty, it, didn't, taste, that, fresh.)]                                                                                          |(16,[0,1,4,6,10,13],[1.0,1.0,1.0,1.0,1.0,1.0])                                                   |\n",
      "|The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.|0     |[the, potatoes, were, like, rubber, and, you, could, tell, they, had, been, made, up, ahead, of, time, being, kept, under, a, warmer.]|(16,[0,1,2,3,4,6,7,8,9,10,11,12,13,15],[3.0,1.0,3.0,1.0,1.0,2.0,3.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|The fries were great too.                                                                                      |1     |[the, fries, were, great, too.]                                                                                                       |(16,[1,2,11,14],[2.0,1.0,1.0,1.0])                                                               |\n",
      "|A great touch.                                                                                                 |1     |[a, great, touch.]                                                                                                                    |(16,[3,14],[2.0,1.0])                                                                            |\n",
      "|Service was very prompt.                                                                                       |1     |[service, was, very, prompt.]                                                                                                         |(16,[6,8,11,12],[1.0,1.0,1.0,1.0])                                                               |\n",
      "|Would not go back.                                                                                             |0     |[would, not, go, back.]                                                                                                               |(16,[3,13,14,15],[1.0,1.0,1.0,1.0])                                                              |\n",
      "|The cashier had no care what so ever on what I had to say it still ended up being wayyy overpriced.            |0     |[the, cashier, had, no, care, what, so, ever, on, what, i, had, to, say, it, still, ended, up, being, wayyy, overpriced.]             |(16,[0,1,3,6,7,8,9,10,12,13,14],[1.0,1.0,2.0,3.0,2.0,3.0,3.0,1.0,1.0,1.0,3.0])                   |\n",
      "|I tried the Cape Cod ravoli, chicken,with cranberry...mmmm!                                                    |1     |[i, tried, the, cape, cod, ravoli,, chicken,with, cranberry...mmmm!]                                                                  |(16,[1,2,10,11,12,14],[1.0,1.0,2.0,1.0,2.0,1.0])                                                 |\n",
      "|I was disgusted because I was pretty sure that was human hair.                                                 |0     |[i, was, disgusted, because, i, was, pretty, sure, that, was, human, hair.]                                                           |(16,[0,3,11,12,13,15],[1.0,1.0,3.0,3.0,1.0,3.0])                                                 |\n",
      "|I was shocked because no signs indicate cash only.                                                             |0     |[i, was, shocked, because, no, signs, indicate, cash, only.]                                                                          |(16,[5,8,11,12,15],[1.0,1.0,3.0,2.0,2.0])                                                        |\n",
      "|Highly recommended.                                                                                            |1     |[highly, recommended.]                                                                                                                |(16,[1],[2.0])                                                                                   |\n",
      "|Waitress was a little slow in service.                                                                         |0     |[waitress, was, a, little, slow, in, service.]                                                                                        |(16,[3,6,7,8,11,13],[1.0,1.0,1.0,1.0,2.0,1.0])                                                   |\n",
      "|This place is not worth your time, let alone Vegas.                                                            |0     |[this, place, is, not, worth, your, time,, let, alone, vegas.]                                                                        |(16,[6,9,10,11,12,13,15],[1.0,1.0,1.0,2.0,1.0,2.0,2.0])                                          |\n",
      "|did not like at all.                                                                                           |0     |[did, not, like, at, all.]                                                                                                            |(16,[2,10,11,13,15],[1.0,1.0,1.0,1.0,1.0])                                                       |\n",
      "+---------------------------------------------------------------------------------------------------------------+------+--------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hashing = HashingTF(inputCol=\"words\", outputCol=\"hashedValues\", numFeatures=pow(2,4))\n",
    "hashed_df = hashing.transform(tokenized)\n",
    "hashed_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d38ded13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+--------------------+\n",
      "|             Reviews|labels|               words|        hashedValues|\n",
      "+--------------------+------+--------------------+--------------------+\n",
      "|Wow... Loved this...|     1|[wow..., loved, t...|(16,[3,6,13],[1.0...|\n",
      "|  Crust is not good.|     0|[crust, is, not, ...|(16,[7,9,10,13],[...|\n",
      "|Not tasty and the...|     0|[not, tasty, and,...|(16,[1,3,6,11,13]...|\n",
      "|Stopped by during...|     1|[stopped, by, dur...|(16,[0,1,2,6,7,8,...|\n",
      "|The selection on ...|     1|[the, selection, ...|(16,[1,2,3,5,8,10...|\n",
      "|Now I am getting ...|     0|[now, i, am, gett...|(16,[0,1,3,10,11,...|\n",
      "|Honeslty it didn'...|     0|[honeslty, it, di...|(16,[0,1,4,6,10,1...|\n",
      "|The potatoes were...|     0|[the, potatoes, w...|(16,[0,1,2,3,4,6,...|\n",
      "|The fries were gr...|     1|[the, fries, were...|(16,[1,2,11,14],[...|\n",
      "|      A great touch.|     1|  [a, great, touch.]|(16,[3,14],[2.0,1...|\n",
      "|Service was very ...|     1|[service, was, ve...|(16,[6,8,11,12],[...|\n",
      "|  Would not go back.|     0|[would, not, go, ...|(16,[3,13,14,15],...|\n",
      "|The cashier had n...|     0|[the, cashier, ha...|(16,[0,1,3,6,7,8,...|\n",
      "|I tried the Cape ...|     1|[i, tried, the, c...|(16,[1,2,10,11,12...|\n",
      "|I was disgusted b...|     0|[i, was, disguste...|(16,[0,3,11,12,13...|\n",
      "|I was shocked bec...|     0|[i, was, shocked,...|(16,[5,8,11,12,15...|\n",
      "| Highly recommended.|     1|[highly, recommen...|      (16,[1],[2.0])|\n",
      "|Waitress was a li...|     0|[waitress, was, a...|(16,[3,6,7,8,11,1...|\n",
      "|This place is not...|     0|[this, place, is,...|(16,[6,9,10,11,12...|\n",
      "|did not like at all.|     0|[did, not, like, ...|(16,[2,10,11,13,1...|\n",
      "+--------------------+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e51b375f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[Reviews: string, labels: string, words: array<string>, hashedValues: vector]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashed_df.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a4363e",
   "metadata": {},
   "source": [
    "# Converting Labelled Column to Numerical Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4a80901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "data_df = hashed_df.withColumn(\"labels\", hashed_df[\"labels\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a65dc6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[Reviews: string, labels: int, words: array<string>, hashedValues: vector]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683f9f32",
   "metadata": {},
   "source": [
    "# Dropping Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b34c32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=data_df.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19a5e7a",
   "metadata": {},
   "source": [
    "# Spliiting Data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fe647bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=data_df.select(\"hashedValues\",\"labels\")\n",
    "train_data,test_data=final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8623d208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|        hashedValues|labels|\n",
      "+--------------------+------+\n",
      "|(16,[3,6,13],[1.0...|     1|\n",
      "|(16,[7,9,10,13],[...|     0|\n",
      "|(16,[1,3,6,11,13]...|     0|\n",
      "|(16,[0,1,2,6,7,8,...|     1|\n",
      "|(16,[1,2,3,5,8,10...|     1|\n",
      "|(16,[0,1,3,10,11,...|     0|\n",
      "|(16,[0,1,4,6,10,1...|     0|\n",
      "|(16,[0,1,2,3,4,6,...|     0|\n",
      "|(16,[1,2,11,14],[...|     1|\n",
      "|(16,[3,14],[2.0,1...|     1|\n",
      "|(16,[6,8,11,12],[...|     1|\n",
      "|(16,[3,13,14,15],...|     0|\n",
      "|(16,[0,1,3,6,7,8,...|     0|\n",
      "|(16,[1,2,10,11,12...|     1|\n",
      "|(16,[0,3,11,12,13...|     0|\n",
      "|(16,[5,8,11,12,15...|     0|\n",
      "|      (16,[1],[2.0])|     1|\n",
      "|(16,[3,6,7,8,11,1...|     0|\n",
      "|(16,[6,9,10,11,12...|     0|\n",
      "|(16,[2,10,11,13,1...|     0|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b41ae9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.readwriter.DataFrameReader at 0x1e3ce2d26d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.format('jdbc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3397e0",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f658094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1e0928b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel: uid=LogisticRegression_e6f4d5e79f6f, numClasses=2, numFeatures=16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model=LogisticRegression(featuresCol=\"hashedValues\",labelCol=\"labels\",maxIter=100, regParam=0.8, elasticNetParam=0.8)\n",
    "model=model.fit(train_data)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3fa8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9097f30",
   "metadata": {},
   "source": [
    "# Predcitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a5fbe66",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+--------------------+----------+\n",
      "|        hashedValues|labels|       rawPrediction|         probability|prediction|\n",
      "+--------------------+------+--------------------+--------------------+----------+\n",
      "|(16,[0,1,2,3,4,5,...|     0|[-0.0321195494221...|[0.49197080291970...|       1.0|\n",
      "|(16,[0,1,2,3,4,5,...|     0|[-0.0321195494221...|[0.49197080291970...|       1.0|\n",
      "|(16,[0,1,2,3,4,5,...|     0|[-0.0321195494221...|[0.49197080291970...|       1.0|\n",
      "|(16,[0,1,2,3,4,5,...|     0|[-0.0321195494221...|[0.49197080291970...|       1.0|\n",
      "|(16,[0,1,2,3,4,5,...|     1|[-0.0321195494221...|[0.49197080291970...|       1.0|\n",
      "|(16,[0,1,2,3,4,5,...|     0|[-0.0321195494221...|[0.49197080291970...|       1.0|\n",
      "|(16,[0,1,2,3,4,5,...|     0|[-0.0321195494221...|[0.49197080291970...|       1.0|\n",
      "|(16,[0,1,2,3,4,5,...|     0|[-0.0321195494221...|[0.49197080291970...|       1.0|\n",
      "|(16,[0,1,2,3,4,5,...|     0|[-0.0321195494221...|[0.49197080291970...|       1.0|\n",
      "|(16,[0,1,2,3,4,5,...|     1|[-0.0321195494221...|[0.49197080291970...|       1.0|\n",
      "|(16,[0,1,2,3,4,5,...|     1|[-0.0321195494221...|[0.49197080291970...|       1.0|\n",
      "|(16,[0,1,2,3,4,6,...|     0|[-0.0321195494221...|[0.49197080291970...|       1.0|\n",
      "|(16,[0,1,2,3,4,6,...|     1|[-0.0321195494221...|[0.49197080291970...|       1.0|\n",
      "|(16,[0,1,2,3,4,6,...|     1|[-0.0321195494221...|[0.49197080291970...|       1.0|\n",
      "|(16,[0,1,2,3,4,7,...|     1|[-0.0321195494221...|[0.49197080291970...|       1.0|\n",
      "|(16,[0,1,2,3,4,8,...|     1|[-0.0321195494221...|[0.49197080291970...|       1.0|\n",
      "|(16,[0,1,2,3,4,8,...|     0|[-0.0321195494221...|[0.49197080291970...|       1.0|\n",
      "|(16,[0,1,2,3,5,6,...|     1|[-0.0321195494221...|[0.49197080291970...|       1.0|\n",
      "|(16,[0,1,2,3,5,6,...|     0|[-0.0321195494221...|[0.49197080291970...|       1.0|\n",
      "|(16,[0,1,2,3,5,6,...|     1|[-0.0321195494221...|[0.49197080291970...|       1.0|\n",
      "+--------------------+------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_prediction = model.transform(test_data)\n",
    "\n",
    "test_prediction.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ac8d42",
   "metadata": {},
   "source": [
    "# Area Under ROC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835fd5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50c59b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_prediction.select('probability', 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e93a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_collect = results.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eba46aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = [(float(i[0][0]), 1.0-float(i[1])) for i in results_collect]\n",
    "scoreAndLabels = sc.parallelize(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dacc437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "382d4d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-value: 0.5\n"
     ]
    }
   ],
   "source": [
    "metrics = BinaryClassificationMetrics(scoreAndLabels)\n",
    "print(\"AUC-value: \" + str(round(metrics.areaUnderROC,4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
